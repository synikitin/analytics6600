<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Analytics 6600</title>
    <link>https://synikitin.github.io/analytics6600/tags/lecture/index.xml</link>
    <description>Recent content on Data Analytics 6600</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Slava Nikitin</copyright>
    <atom:link href="/tags/lecture/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Case Study 2</title>
      <link>https://synikitin.github.io/analytics6600/post/case2/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://synikitin.github.io/analytics6600/post/case2/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;div id=&#34;conference-proceedings-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conference Proceedings Analysis&lt;/h2&gt;
&lt;div id=&#34;project&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;br /&gt;
A retail company XYZ LLC prides itself on excellent customer service. One way to deliver excellence is by listening to customer complaints about their products and services collected through various channels like email or phone. Upon receiving a complaint, it is supposed to go through a classification process assigning it a product, sub-product and progressively detailed reasons for the complaint. The purpose of the classes is to organize complaints, and enable calculation of descriptive statistics and trending to get a better insight into what needs to be adjusted and how to prioritize work. However, being a large company with many and multifaceted products, the classification tree is deep and broad. During each complaint classification cycle, a complaint can pass through subtrees with options in the dozens which is a heavy cognitive load on the customer associate. The heavy load translates into slow downs, avoidance of work, missing data, poor data quality, a need for a quality assurance process, job dissatisfaction and increased turnover. All these negative side-effects undermine delivery of excellent customer service and impose extra costs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;br /&gt;
The central task is to make the classification process much easier to reduce or eliminate its negative side-effects. Provide a wrapper around the code such that it can integrate into the existing user interface and improve the current classification process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Benefits&lt;/strong&gt;&lt;br /&gt;
Making the classification process substantially easier will lead to&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Specification&lt;/strong&gt;&lt;br /&gt;
Few years of complaints data in .csv will be provided to support the work.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;br /&gt;
Use the data generated by the complaint classification process to develop a predictive model that can take complaint text and predict class probabilities. Computed class probabilities can be used to sort the classes and only show the most likely batch. This will produce a dynamic classification process that will be sensitive to the information in the complaint and guide the customer associate towards the most fitting classes without completely removing them out of the process.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;people&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;People&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A project manager, a data scientist and a developer from Awesome Analytics.&lt;/li&gt;
&lt;li&gt;An expert on the complaint data and the user interface, a customer associate, developers responsible for the user interface from XYZ.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;process&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Process&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Phases&lt;/strong&gt;&lt;br /&gt;
Emphasize, Define, Ideate, Prototype, Test, Implement&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;&lt;br /&gt;
Weekly meetings will take place to collect feedback.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security Classification&lt;/strong&gt;&lt;br /&gt;
Data is private.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;issues-ideas-and-principles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Issues, Ideas and Principles&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;br /&gt;
A predictive model integrated into an interactive user interface rather than understanding or automated actions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Confidentiality&lt;/strong&gt;&lt;br /&gt;
Complaint data has personally identifying as well as business sensitive information.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Transfer&lt;/strong&gt;&lt;br /&gt;
Private data requires a more serious consideration of data transfer. For example, working on site or placing a machine in client’s environment or establishing direct, encrypted transfer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Management&lt;/strong&gt;&lt;br /&gt;
With confidential data you have to worry about access, provinence, and potentially destruction. A good access principle to follow is limitting access project materials only to those actually working the projects. Provinence involves recording the trail of the data as it moves around and is modified. Finally, data destruction upon project completion is a good, risk-averse practice.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Formats&lt;/strong&gt;&lt;br /&gt;
A .csv format is really typical, but can be generated in various ways as there is no commonly agreed upon specification. Commas and new line characters and double quotes can appear in text fields, and without properly quoting them, the separation of cells or lines can get lost.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Complex Transformations&lt;/strong&gt;&lt;br /&gt;
How to transform a piece of text into a class, especially when text is highly variable and there are hundreds of classes? No intuitive answer comes - the problem is complex, and manually constructed rules will do poorly and take enourmous time to develop. Data, however, contains many examples of what class was assigned to a piece of text. Statistical models can be used to represent a large number of possible relationship between text and class, and then data be used to find the relationship most consistent with data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assessment of Predictive Models&lt;/strong&gt;&lt;br /&gt;
We can split the data into two, one part for learning a relationship of text and class consistent with data, another for testing its accuracy. We could calculate overall accuracy as well as class specific accuracies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interpretability of Predictive Models&lt;/strong&gt;&lt;br /&gt;
Complex non-linear mathematical functions are learned to represent the relationship of text and class. What if someone wanted to know what pieces of information in the complaint contributed to it being classified in some way? Interpretability is an important aspect of understanding the learned model and providing reasons for the automated predictions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conditions of Application&lt;/strong&gt;&lt;br /&gt;
In this case, applying the predictive model to the whole classification tree is unnecessary and not possible from the beginning. In this project, the most impact can be achieved by considering subtrees that have more than 5 options, have sufficient data and can be handled accurately by the model.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kinds and Gradations of Automation&lt;/strong&gt;&lt;br /&gt;
This is an example of outsourcing some mental work to a machine. If a task is repeatable and can be broken down into steps, then we can think of sharing those steps between a human and a machine, with the balance roughly giving you the amount of automation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improvement over Time&lt;/strong&gt; A system built on data can often improve with more data. In this case, predictive models will get more accurate, more parts of the classification tree can be reached systematically by a customer associate and generate data to build additional models. By putting some predictive models into a system sets a company on a trajectory of improvements.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;relevant-r-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Relevant R packages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Import&lt;/strong&gt;&lt;br /&gt;
readr&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transform&lt;/strong&gt;&lt;br /&gt;
dplyr, stringr, text2vec&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualize&lt;/strong&gt;&lt;br /&gt;
ggplot2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;br /&gt;
xgboost, lime&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automate&lt;/strong&gt; R packaging system&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Case Study 1</title>
      <link>https://synikitin.github.io/analytics6600/post/case1_abstracts/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://synikitin.github.io/analytics6600/post/case1_abstracts/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;div id=&#34;conference-proceedings-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conference Proceedings Analysis&lt;/h2&gt;
&lt;div id=&#34;project&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;br /&gt;
A health care company XYZ LLC hosts conferences on novel variants of cancer and technologies meant to detect it early. Scientists in charge of it are responsible for preparing a summary presentation of past and present research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;br /&gt;
Understand origins of authors, co-author network, novel variants of cancer, clusters of abstracts based on similar topics, trends across the last decade in most prominent research topics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Benefits&lt;/strong&gt;&lt;br /&gt;
Maintain reputation of thought leadership in the area of cancer research, advance knowledge by submitting a paper into a proceedings journal based on the trends, come up with a repeatable, automated process, potentially &lt;strong&gt;reuse&lt;/strong&gt; the process as a service to meet the demand of understanding ongoing trends in technology.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Specification&lt;/strong&gt;&lt;br /&gt;
Data from prior conferences in .docx, .pdf, .xlsx, .csv will be provided to support the work.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;br /&gt;
Visuals for the 5 objectives will be provided with appropriate resolution as .jpeg images. Code underlying all the data preparation and analysis will be provided, too.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;people&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;People&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A project manager and a data scientist from Awesome Analytics.&lt;/li&gt;
&lt;li&gt;A cancer scientist from the client to guide the design and aesthetic features of the visuals.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;process&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Process&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Phases&lt;/strong&gt;&lt;br /&gt;
Emphasize, Define, Ideate, Prototype, Test, Implement&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;&lt;br /&gt;
Weekly meetings will take place to collect feedback.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security Classification&lt;/strong&gt;&lt;br /&gt;
Data is public.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;issues-ideas-and-principles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Issues, Ideas and Principles&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;br /&gt;
Understanding of conference authors and research trends, not simple data summaries or prediction or technology. Maybe a technology - a program rerun each conference.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Confidentiality&lt;/strong&gt;&lt;br /&gt;
Transmission of public data does not pose much issue: email is a valid method. Things get more complicated with private or classified data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Formats&lt;/strong&gt;&lt;br /&gt;
Text data can be stored on disk using many formats, each requiring its own parsing methods to convert text into a common representation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Encoding&lt;/strong&gt;&lt;br /&gt;
Technical abstracts are submitted from around the world. Text in abstracts contains many special symbols and letters from other alphabets. These are handled by an expanded character set, called UTF-8, but may require special handling when cleaning text.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Collection&lt;/strong&gt;&lt;br /&gt;
Generated by humans with a non-standard process which creates much nuisance variation in data, say how names and countries are written down, that complicates data preparation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sources of variation&lt;/strong&gt;&lt;br /&gt;
Key idea in dealing with much data, including messy text, is to think of it in terms of variable components that combine together to make the observed data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automated Tools vs Manual Rules&lt;/strong&gt;&lt;br /&gt;
Data with nuisance variation breaks assumptions of automated tools and often requires creation of manually crafted rules, one by one, through trial and error. Regular expression and dictionaries are key technologies. This, of course, slows down work quite a bit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simple versus Complex Transformations&lt;/strong&gt;&lt;br /&gt;
The questions of author origins and cooperation can be obtained through straightforward manipulations of the provided data. However, finding novel variants of cancer, clustering abstracts by topic or trending research topics over time is not as clear-cut. The later set of problems requires statistical models to give us algorithms that can output probabilities, topics, and clusters.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;relevant-r-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Relevant R packages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;&lt;br /&gt;
state.abb, mapdata&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Import&lt;/strong&gt;&lt;br /&gt;
readxl, readr, pdftools&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tidy&lt;/strong&gt;&lt;br /&gt;
tidytext, tidygraph&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transform&lt;/strong&gt;&lt;br /&gt;
xml2, dplyr, stringr&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualize&lt;/strong&gt;&lt;br /&gt;
ggplot2, ggrepel&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;br /&gt;
topicmodels&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Communicate&lt;/strong&gt;&lt;br /&gt;
Rmarkdown&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://synikitin.github.io/analytics6600/post/intro/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://synikitin.github.io/analytics6600/post/intro/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;div id=&#34;outline&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Outline&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Introductions&lt;/li&gt;
&lt;li&gt;Analytics as a Layer of Digital Transformations&lt;/li&gt;
&lt;li&gt;Introduction to R&lt;/li&gt;
&lt;li&gt;Installation of RStudio&lt;/li&gt;
&lt;li&gt;Demo of Programming in RStudio&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;data-science-as-a-layer-of-digital-transformation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Science as a Layer of Digital Transformation&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://synikitin.github.io/analytics6600/img/digital.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cycles-of-innovation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cycles of Innovation&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/3/33/Spiral_model_%28Boehm%2C_1988%29.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;problem-driven-innovation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Problem-Driven Innovation&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://synikitin.github.io/analytics6600/img/design_circle.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analytics-producer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analytics Producer:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Roles: Data scientists, software developers, infrastructure engineers, business analysts, subject matter experts&lt;/li&gt;
&lt;li&gt;Backgrounds: Math/stats, social sciences, economics, computer science&lt;/li&gt;
&lt;li&gt;Skills: Math/statistics, communications, domain expertise, “end-to-end”&lt;/li&gt;
&lt;li&gt;Key Attributes: Curiosity, a desire to learn, a willingness to get hands dirty&lt;/li&gt;
&lt;li&gt;Culture: Work in close proximity, exposure to variety of problems, safe to question, acceptable failure rate&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analytics-client&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analytics Client:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Available data and an SME (can someone plug in a laptop and query the data?)&lt;/li&gt;
&lt;li&gt;Business lead (provides guidance, removes roadblocks, serves as sounding board)&lt;/li&gt;
&lt;li&gt;Quantifying the value to be created&lt;/li&gt;
&lt;li&gt;Understanding the existing workflow (flowcharts are your friend)&lt;/li&gt;
&lt;li&gt;Access to a real live user in the wild&lt;/li&gt;
&lt;li&gt;Well-defined scope, in writing&lt;/li&gt;
&lt;li&gt;Frequent communications with feedback (design sessions)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;data-science-cycle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Science Cycle&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://synikitin.github.io/analytics6600/img/data-science.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;application-to-wait-time-prediction-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Application to Wait Time Prediction Project&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://synikitin.github.io/analytics6600/img/waittime.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;technical-ecosystem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Technical Ecosystem&lt;/h2&gt;
&lt;p&gt;Overview of R and Rstudio ecosystem: &lt;a href=&#34;http://fg2re.sellorm.com&#34; class=&#34;uri&#34;&gt;http://fg2re.sellorm.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
  </channel>
</rss>
